{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker as tk\n",
    "import scipy as sp\n",
    "\n",
    "rPath = \"RESULTS/variations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is important that these be arrays because they need to be\n",
    "# in the same order as the parameters.h file\n",
    "pops = [\"V1L4E\", \"V1L4I\", \"V1L23E\", \"V1L23I\", \"V2L4E\", \"V2L4I\", \"V2L23E\", \"V2L23I\", \"LGN\"]\n",
    "dims = {\"V1L4E\":[23,4], \"V1L4I\":[23,1], \"V1L23E\":[17,7], \"V1L23I\":[17,2], \"V2L4E\":[13,10], \"V2L4I\":[13,3], \"V2L23E\":[10,16], \"V2L23I\":[10,5], \"LGN\":[32,2]}\n",
    "RFsv = {\"FF\":{\"V1L4\":10, \"V1L23\":7, \"V2L4\":5, \"V2L23\":4}, \"Lat\":{\"V1L4\":11, \"V1L23\":9, \"V2L4\":7, \"V2L23\":5}, \"FB\":{\"V1L4\":7, \"V1L23\":8, \"V2L4\":4, \"V2L23\":0}}\n",
    "syns = [ [\"LGN\", \"V1L4E\", \"FF\"], [\"LGN\", \"V1L4I\", \"FF\"], [\"V1L4E\", \"V1L23E\", \"FF\"], [\"V1L4E\", \"V1L23I\", \"FF\"], \n",
    "    [\"V1L23E\", \"V2L4E\", \"FF\"], [\"V1L23E\", \"V2L4I\", \"FF\"], [\"V2L4E\", \"V2L23E\", \"FF\"], [\"V2L4E\", \"V2L23I\", \"FF\"],\n",
    "    [\"V1L4E\", \"V1L4I\", \"Lat\"], [\"V1L4I\", \"V1L4E\", \"Lat\"], [\"V1L4I\", \"V1L4I\", \"Lat\"], [\"V1L23E\", \"V1L23I\", \"Lat\"],\n",
    "    [\"V1L23I\", \"V1L23E\", \"Lat\"], [\"V1L23I\", \"V1L23I\", \"Lat\"], [\"V2L4E\", \"V2L4I\", \"Lat\"], [\"V2L4I\", \"V2L4E\", \"Lat\"], \n",
    "    [\"V2L4I\", \"V2L4I\", \"Lat\"], [\"V2L23E\", \"V2L23I\", \"Lat\"], [\"V2L23I\", \"V2L23E\", \"Lat\"], [\"V2L23I\", \"V2L23I\", \"Lat\"], \n",
    "    [\"V2L23E\", \"V1L23E\", \"FB\"], [\"V2L23E\", \"V1L23I\", \"FB\"],  [\"V1L23E\", \"V1L4I\", \"FB\"], [\"V2L23E\", \"V2L4I\", \"FB\"], \n",
    "    [\"V1L4I\", \"V1L23E\", \"FF\"], [\"V1L4I\", \"V1L23I\", \"FF\"], [\"V2L4I\", \"V2L23E\", \"FF\"], [\"V2L4I\", \"V2L23I\", \"FF\"] ]\n",
    "sNames = [ s[0]+\"-\"+s[1] for s in syns]\n",
    "\n",
    "vars = [\"trace\", \"average\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rAvg = {}\n",
    "wAvg = {}\n",
    "rHist = {}\n",
    "for i, v in enumerate(vars):\n",
    "    rAvg[v] = pd.read_csv(rPath+v+\"/training/avgRates.tsv\", sep=\"\\t\")\n",
    "    wAvg[v] = pd.read_csv(rPath+v+\"/training/avgWeights.tsv\", sep=\"\\t\")\n",
    "    # Load distirbutions\n",
    "    dist = {}\n",
    "    for p in pops:\n",
    "        dist[p] = {\"count\":[], \"bins\":[]}\n",
    "        with open(rPath+v+\"/training/\"+p+\"dist.vec\") as f:\n",
    "            for i, r in enumerate(f):\n",
    "                if (i%2 == 0): dist[p][\"count\"].append(np.fromstring(r, sep=\" \"))\n",
    "                else: dist[p][\"bins\"].append(np.fromstring(r, sep=\" \"))\n",
    "        rHist[v] = dist\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tA = {v:{} for v in vars}\n",
    "tTH = {v:{} for v in vars}\n",
    "for v in vars:\n",
    "    for p in pops[:-1]:\n",
    "        tA[v][p] = np.loadtxt(rPath+v+\"/training/a\"+p)\n",
    "        tTH[v][p] = np.loadtxt(rPath+v+\"/training/theta\"+p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity levels\n",
    "fig, axs = plt.subplots(2,2, figsize = (13,7))\n",
    "for i,v in enumerate(vars):\n",
    "    # Smoothed rates\n",
    "    rAvg[v][pops].apply(lambda x : sp.signal.savgol_filter(x,20,2)).plot(ax=axs[i][0], legend=False)\n",
    "    axs[i][0].set_title(v+\" target\")\n",
    "    # Signal retention\n",
    "    rAvg[v][pops[:-1]].apply(lambda x : x/rAvg[v][pops[-1]]).apply(lambda x : sp.signal.savgol_filter(x,20,2)).plot(ax=axs[i][1])\n",
    "    axs[i][1].set_title(\"input normalised signal\")\n",
    "    axs[i][1].legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "\n",
    "\n",
    "#plt.savefig(rPath+\"training_sum/avgRates.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Activity\n",
    "fig, axs = plt.subplots(3,1, figsize = (6,4))\n",
    "for i,v in enumerate(vars):\n",
    "    # No activity\n",
    "    rAvg[v].where(rAvg[v]==0)[pops[:-1]].apply(lambda x : x+.1*(pops.index(x.name))).plot(ax=axs[i], legend=False)\n",
    "    axs[i].set_xlim(0,200)\n",
    "    axs[i].set_yticks([])\n",
    "    axs[i].set_ylabel(v)\n",
    "\n",
    "axs[0].set_xticks([])\n",
    "axs[1].set_xticks([])\n",
    "h,l = axs[0].get_legend_handles_labels()\n",
    "fig.legend(h,l, loc='center left', bbox_to_anchor=(.95, .67), )\n",
    "fig.suptitle(\"Zero-average activity\")\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average last 10 records\n",
    "#pd.concat([rAvg[v][pops[:-1]].tail(10).mean() for v in vars],axis=1, keys=vars)\n",
    "pd.concat([rAvg[v][pops[:-1]].tail(10).agg([\"mean\", \"std\"]).transpose() for v in vars],axis=1, keys=vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity Distributions\n",
    "for v in vars:\n",
    "    fig, axs = plt.subplots(len(pops[:-1]),4, figsize=(20,10))\n",
    "    toshow = [1, 50, 100, 200]\n",
    "    for k,p in enumerate(pops[:-1]):\n",
    "        h = rHist[v][p]\n",
    "        axs[k][0].text(-.2,.5,p, transform = axs[k][0].transAxes)\n",
    "        for i, t in enumerate(toshow):\n",
    "            axs[k][i].bar(h[\"bins\"][t][1:-1], h[\"count\"][t][1:], width=h[\"bins\"][t][1]*.8, align='center')\n",
    "            axs[k][i].bar(rAvg[v][p].values[t], max(h[\"count\"][t][1:]), width=h[\"bins\"][t][1]*.6, color=\"red\")\n",
    "            perc = 100*(1.-h[\"count\"][t][0]/sum(h[\"count\"][t]))\n",
    "            axs[k][i].text(.9,.8, str(round(perc,2))+\"%\" if perc > .01  else \"> .01%\", fontsize=8,transform=axs[k][i].transAxes)\n",
    "\n",
    "    for i, t in enumerate(toshow): axs[0][i].set_title(str(t*1000) + \" patches\")\n",
    "    fig.suptitle(v)\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plastic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrinsic plasticity\n",
    "for v in vars:\n",
    "    fig, axs = plt.subplots(4,2, figsize = (10,5))\n",
    "    for i,p in enumerate(pops[:4]):\n",
    "        c,b,_ = axs[i][0].hist(tA[v][p], 40)\n",
    "        axs[i][0].bar(tA[v][p].mean(), c.max(),width=(b[1]-b[0])*.3, color=\"red\")\n",
    "        axs[i][0].text(-.25,.5,p, transform = axs[i][0].transAxes)\n",
    "        c,b,_ = axs[i][1].hist(tTH[v][p], 40)\n",
    "        axs[i][1].bar(tTH[v][p].mean(), c.max(),width=(b[1]-b[0])*.3, color=\"red\")\n",
    "    axs[0][0].set_title(\"a\")\n",
    "    axs[0][1].set_title(r'$\\theta$')\n",
    "    fig.suptitle(v)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipStats = []\n",
    "for v in vars:\n",
    "    meanA = []\n",
    "    meanT = []\n",
    "    stdA = []\n",
    "    stdT = []\n",
    "    for p in pops[:-1]:\n",
    "        meanA.append(tA[v][p].mean())\n",
    "        stdA.append(tA[v][p].std())\n",
    "        meanT.append(tTH[v][p].mean())\n",
    "        stdT.append(tTH[v][p].std())\n",
    "    A = pd.DataFrame({\"mean\":meanA, \"std\":stdA}, index=pops[:-1])\n",
    "    T = pd.DataFrame({\"mean\":meanT, \"std\":stdT}, index=pops[:-1])\n",
    "    ipStats.append(pd.concat([A,T], axis=1, keys=[\"a\",\"theta\"]))\n",
    "ipStats = pd.concat(ipStats, axis=1, keys=vars)\n",
    "ipStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average weights\n",
    "for v in vars:\n",
    "    fig,axs = plt.subplots(int(len(pops)/3), 3, figsize = (12, 6))\n",
    "    for i,p in enumerate(pops):\n",
    "        cols = [c for c in wAvg[v].columns if p+\"-\" in c]\n",
    "        wAvg[v][cols].plot(ax=axs[int(i/3)][i%3])\n",
    "        axs[int(i/3)][i%3].set_title(p, fontsize=10)\n",
    "        axs[int(i/3)][i%3].legend(title=\"Target\", labels=[c.split(\"-\")[1] for c in cols], fontsize=8)\n",
    "    fig.suptitle(v, fontsize=11)\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights distributions\n",
    "for v in vars[:1]:\n",
    "    fig,axs = plt.subplots(int(len(syns)/4), 4, figsize = (15, 20))\n",
    "    for i,s in enumerate(syns):\n",
    "        sName = s[0]+\"-\"+s[1]\n",
    "        ax = axs.flatten()[i]\n",
    "        mat = np.loadtxt(rPath+v+\"/training/\"+sName+\"weights.vec\")\n",
    "        mask = np.loadtxt(\"rateModel/architecture/matrices/\"+sName)\n",
    "        ws = mat[mask !=0]\n",
    "        ws = ws[ws!=0]\n",
    "        wM = ws.mean()\n",
    "        wStd = ws.std()\n",
    "        ws = ws[ws < wM+wStd*4]\n",
    "        c, b, _ = ax.hist(ws, 50)\n",
    "        ax.bar(x=wM,height=c.max(), width = b[1]*.6, color=\"red\")\n",
    "\n",
    "        form = tk.ScalarFormatter(useMathText=True)\n",
    "        form.set_scientific(True)\n",
    "        form.set_powerlimits((-1,1)) \n",
    "\n",
    "        ax.get_yaxis().set_major_formatter(form)\n",
    "        ax.text(.5,.9,sName, transform=ax.transAxes)\n",
    "    fig.suptitle(v, fontsize = 12)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights distributions - selected\n",
    "lb = [\"a)\",\"b)\",\"c)\",\"d)\",\"e)\",\"f)\",\"g)\",\"h)\"]\n",
    "for v in vars:\n",
    "    fig,axs = plt.subplots(4, 2, figsize = (9, 8))\n",
    "    for i,sName in enumerate([\"LGN-V1L4E\", \"LGN-V1L4I\", \"V1L4E-V1L4I\",\"V1L4I-V1L4E\", \"V2L4E-V2L23E\", \"V1L4I-V1L4I\", \"V2L23E-V2L23I\", \"V2L23I-V2L23E\"]):\n",
    "        ax = axs.flatten()[i]\n",
    "        mat = np.loadtxt(rPath+v+\"/training/\"+sName+\"weights.vec\")\n",
    "        mask = np.loadtxt(\"rateModel/architecture/matrices/\"+sName)\n",
    "        ws = mat[mask !=0]\n",
    "        ws = ws[ws!=0]\n",
    "        wM = ws.mean()\n",
    "        wStd = ws.std()\n",
    "        ws = ws[ws < wM+wStd*4]\n",
    "        c, b, _ = ax.hist(ws, 50)\n",
    "        ax.vlines(x=wM,ymin=0, ymax=c.max(), color=\"red\")\n",
    "        ax.text(-.2,1,lb[i], fontsize=16, transform=ax.transAxes)\n",
    "\n",
    "        form = tk.ScalarFormatter(useMathText=True)\n",
    "        form.set_scientific(True)\n",
    "        form.set_powerlimits((-1,1)) \n",
    "\n",
    "        ax.get_yaxis().set_major_formatter(form)\n",
    "        ax.text(.7,.9,sName, transform=ax.transAxes)\n",
    "    fig.suptitle(v, fontsize = 12)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights stats\n",
    "stats = []\n",
    "for v in vars:\n",
    "    means = []\n",
    "    stds = []\n",
    "    idx = []\n",
    "    for i,s in enumerate(syns):\n",
    "        sName = s[0]+\"-\"+s[1]\n",
    "#        if s[2] != \"FF\": continue\n",
    "        mat = np.loadtxt(rPath+v+\"/training/\"+sName+\"weights.vec\")\n",
    "        mask = np.loadtxt(\"rateModel/architecture/matrices/\"+sName)\n",
    "        ws = mat[mask !=0]\n",
    "        means.append(ws.mean())\n",
    "        stds.append(ws.std())\n",
    "        idx.append(sName)\n",
    "        #ws = ws[ws!=0]\n",
    "    stats.append(pd.DataFrame({\"mean\":np.round(means,3), \"std\":np.round(stds,2)}, index=idx))\n",
    "stats = pd.concat(stats, axis = 1, keys=vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inh = [ c for c in stats.index if c.split(\"-\")[0][-1]==\"I\"]\n",
    "#exc = [ c for c in stats.index if c.split(\"-\")[0][-1]!=\"I\"]\n",
    "\n",
    "# Weights stats\n",
    "stats = {v:{} for v in vars}\n",
    "for v in vars:\n",
    "    inh = []\n",
    "    exc = []\n",
    "    for i,s in enumerate(syns):\n",
    "        sName = s[0]+\"-\"+s[1]\n",
    "        mat = np.loadtxt(rPath+v+\"/training/\"+sName+\"weights.vec\")\n",
    "        mask = np.loadtxt(\"rateModel/architecture/matrices/\"+sName)\n",
    "        ws = mat[mask !=0]\n",
    "        if s[0][-1] == \"I\": inh.append(ws.flatten())\n",
    "        else: exc.append(ws)\n",
    "    stats[v][\"inh\"] = np.concatenate(inh)\n",
    "    stats[v][\"exc\"] = np.concatenate(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.ttest_ind(stats[\"trace\"][\"inh\"], stats[\"average\"][\"inh\"], alternative = \"less\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receptive Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights stats\n",
    "stats = []\n",
    "for v in vars:  \n",
    "    means = []\n",
    "    stds = []\n",
    "    idx = []\n",
    "    for i,s in enumerate(syns):\n",
    "        sName = s[0]+\"-\"+s[1]\n",
    "        if s[2] != \"FF\": continue\n",
    "        mat = np.loadtxt(rPath+v+\"/training/\"+sName+\"weights.vec\")\n",
    "        mask = np.loadtxt(\"rateModel/architecture/matrices/\"+sName)\n",
    "        ws = mat[mask !=0]\n",
    "        means.append(ws.mean())\n",
    "        stds.append(ws.std())\n",
    "        idx.append(sName)\n",
    "        #ws = ws[ws!=0]\n",
    "    stats.append(pd.DataFrame({\"mean\":np.round(means,3), \"std\":np.round(stds,2)}, index=idx))\n",
    "stats = pd.concat(stats, axis = 1, keys=vars)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in vars[:1]:\n",
    "    for s in syns[:2]:\n",
    "        sName = s[0]+\"-\"+s[1]\n",
    "        mat = np.loadtxt(rPath+v+\"/training/\"+sName+\"weights.vec\")\n",
    "        mask = np.loadtxt(\"rateModel/architecture/matrices/\"+sName)\n",
    "        fE, axE = plt.subplots(10, 10, figsize = (10,10))\n",
    "        fE.suptitle(sName+\" On\", y=.92)    \n",
    "        fI, axI = plt.subplots(10, 10, figsize = (10,10))\n",
    "        fI.suptitle(sName+\" Off\", y=.92)\n",
    "        fRF, axRF = plt.subplots(10, 10, figsize = (10,10))\n",
    "        fRF.suptitle(sName+\" Receptive Fields\", y=.92)\n",
    "        for i in range(100):\n",
    "            rf = mat[:,100+i][mask[:,100+i]!=0.].reshape(10,10,2)\n",
    "            exc = rf[:,:,0]/rf[:,:,0].max()\n",
    "            inh = rf[:,:,1]/rf[:,:,1].max()\n",
    "            axE[i//10][i%10].matshow(exc, cmap=plt.cm.Blues)\n",
    "            axE[i//10][i%10].set_xticks([],[])\n",
    "            axE[i//10][i%10].set_yticks([],[])\n",
    "            axI[i//10][i%10].matshow(inh, cmap=plt.cm.Reds)\n",
    "            axI[i//10][i%10].set_xticks([],[])\n",
    "            axI[i//10][i%10].set_yticks([],[])\n",
    "            axRF[i//10][i%10].matshow(inh-exc, cmap=plt.cm.bwr)\n",
    "            axRF[i//10][i%10].set_xticks([],[])\n",
    "            axRF[i//10][i%10].set_yticks([],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [\"a)\", \"b)\", \"c)\", \"d)\"]\n",
    "lbi = 0\n",
    "for v in vars:\n",
    "    for s in syns[:2]:\n",
    "        sName = s[0]+\"-\"+s[1]\n",
    "        mat = np.loadtxt(rPath+v+\"/training/\"+sName+\"weights.vec\")\n",
    "        mask = np.loadtxt(\"rateModel/architecture/matrices/\"+sName)\n",
    "        fRF, axRF = plt.subplots(10, 10, figsize = (7,7))\n",
    "        fRF.suptitle(s[1], y=.92)\n",
    "        fRF.text(0.1,.9,lb[lbi], fontsize=16)\n",
    "        lbi+=1\n",
    "        for i in range(100):\n",
    "            rf = mat[:,100+i][mask[:,100+i]!=0.].reshape(10,10,2)\n",
    "            exc = rf[:,:,0]/rf[:,:,0].max()\n",
    "            inh = rf[:,:,1]/rf[:,:,1].max()\n",
    "            if True: # Separate versus joint scaling\n",
    "                vrf = inh-exc\n",
    "            else:\n",
    "                vrf = rf[:,:,1]-rf[:,:,0]\n",
    "                vrf /= np.abs(vrf.flatten()).max()\n",
    "\n",
    "            axRF[i//10][i%10].matshow(vrf, cmap=plt.cm.bwr)\n",
    "            axRF[i//10][i%10].set_xticks([],[])\n",
    "            axRF[i//10][i%10].set_yticks([],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit as cf\n",
    "import math as m\n",
    "import random as r\n",
    "from sklearn.metrics import mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gab(c, sx, sy, f, th, phi, A, B):\n",
    "    x = c%10\n",
    "    y = np.floor(c/10)\n",
    "    x1 = x*np.cos(th)+y*np.sin(th)\n",
    "    y1 = -x*np.sin(th)+y*np.cos(th)\n",
    "    xp = -(x1**2/(2*sx**2))-(y1**2/(2*sy**2))\n",
    "    return A*np.exp(xp)*np.cos(2*m.pi*f*x1-phi)+B\n",
    "\n",
    "def find_ext(x, y):\n",
    "    try:\n",
    "        p,_,inf,_,_ = cf(gab,x,y, p0=[r.uniform(0,10),r.uniform(0,10), r.uniform(0,100), 6.28*r.random(), 6.28*r.random(), r.uniform(0,5), r.random()], full_output=True)\n",
    "        err = mae(y, inf[\"fvec\"])\n",
    "        return p[0], p[1], p[3], err\n",
    "    except RuntimeError:\n",
    "        return 0,0,0,-1\n",
    "\n",
    "for v in vars:\n",
    "    for s in syns[:2]:\n",
    "        sName = s[0]+\"-\"+s[1]\n",
    "        mat = np.loadtxt(rPath+v+\"/training/\"+sName+\"weights.vec\")\n",
    "        mask = np.loadtxt(\"rateModel/architecture/matrices/\"+sName)\n",
    "        pars = {\"sx\":[], \"sy\":[], \"th\":[], \"err\":[]}\n",
    "        for i in list(range(mat.shape[1])):\n",
    "            rf = mat[:,i][mask[:,i]!=0.].reshape(10,10,2)\n",
    "            exc = rf[:,:,0]/rf[:,:,0].max()\n",
    "            inh = rf[:,:,1]/rf[:,:,1].max()\n",
    "            rf = inh-exc\n",
    "            x = [i for i in range(100)]\n",
    "            y = rf.flatten()\n",
    "            sx, sy, th = 0,0,0\n",
    "            err = 1000000000\n",
    "            for _ in range(100):\n",
    "                nErr = -1\n",
    "                while nErr == -1:\n",
    "                    Tsx, Tsy, Tth, nErr = find_ext(x, y)\n",
    "                if nErr < err:\n",
    "                    err = nErr\n",
    "                    sx = Tsx\n",
    "                    sy = Tsy\n",
    "                    th = Tth\n",
    "            pars[\"sx\"].append(sx)\n",
    "            pars[\"sy\"].append(sy)\n",
    "            pars[\"th\"].append(th)\n",
    "            pars[\"err\"].append(err)\n",
    "        pd.DataFrame(pars).to_csv(rPath+v+\"/training/\"+sName+\"extents.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fRF, axRF = plt.subplots(4, 2, figsize = (7,7))\n",
    "for v in vars:\n",
    "    for s in syns[:2][:-1]:\n",
    "        sName = s[0]+\"-\"+s[1]\n",
    "        tar = s[1]\n",
    "        p = pd.read_csv(rPath+v+\"/training/\"+sName+\"extents.csv\")\n",
    "        # Sign has no meaning\n",
    "        p[\"sx\"] = np.absolute(p[\"sx\"].values)\n",
    "        p[\"sy\"] = np.absolute(p[\"sy\"].values)\n",
    "        # Extents \n",
    "        p.loc[p[\"sx\"] > 10, \"sx\"] = np.nan\n",
    "        p.loc[p[\"sy\"] > 10, \"sy\"] = np.nan\n",
    "p[[\"sx\",\"sy\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
