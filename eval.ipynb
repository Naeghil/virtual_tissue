{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pops = [\"V1L4E\", \"V1L4I\", \"V1L23E\", \"V1L23I\", \"V2L4E\", \"V2L4I\", \"V2L23E\", \"V2L23I\"]\n",
    "sets = [\"MNIST_train\",\"MNIST_test\",\"CIFAR-10_test_gray\",\"CIFAR-10_train_gray\",\"SVHN_test\",\"SVHN_train\", \"EMNIST_test\",\"EMNIST_train\",\"ETH80_gray_vector\",\"CalTec101_subset\"]#CalTec101_images,STL10_train,STL10_test\n",
    "#sets = [\"MNIST_train\",\"MNIST_test\",\"CIFAR-10_test_gray\",\"CIFAR-10_train_gray\",\"SVHN_test\",\"SVHN_train\", \"ETH80_gray_vector\",\"CalTec101_subset\"]#CalTec101_images,STL10_train,STL10_test\n",
    "noImgs = [60000,10000,10000,50000,26032,73257,18800,112800,3280,1233]\n",
    "#conditions = [\"30on\", \"30off\", \"42on\", \"42off\", \"100on\", \"100off\"]\n",
    "times = [\"30\", \"100\", \"42\"]\n",
    "feedback = [\"on\",\"off\"]\n",
    "vars = [\"trace\",\"average\"]\n",
    "accuracies = pd.DataFrame(columns=[\"Dataset\",\"Recording Time\", \"Feedback\", \"Population\", \"Accuracy\", \"Variation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evPath = \"../RESULTS/variations/\"+vars[0]+\"eval/\"+feedback[0]+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "for i,s in enumerate(sets):\n",
    "    ds.append(np.concatenate([np.loadtxt(\"../DATA/\"+s+\"/\"+str(k)) for k in range(noImgs[i])]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5,2, figsize = (10,15))\n",
    "for i,s in enumerate(ds):\n",
    "    sl = len(s)\n",
    "    tmp = s[s!=0]\n",
    "    c, b, _ = axs.flatten()[i].hist(tmp, 100)\n",
    "    axs.flatten()[i].bar(tmp.mean(), c.max(), width=b[1]*.8, color = \"red\")\n",
    "    axs.flatten()[i].text(.9, .9, 100*len(tmp)/sl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in vars:\n",
    "    path = \"../RESULTS/variations/\"+v+\"/\"\n",
    "    acc = pd.concat([pd.read_csv(path+\"accuracieson.csv\", index_col=0), pd.read_csv(path+\"accuraciesoff.csv\", index_col=0)])\n",
    "    acc.drop_duplicates().to_csv(path+\"accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../RESULTS/variations/\"+vars[0]+\"/\"\n",
    "acc = pd.read_csv(path+\"accuracies.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc[\"trace\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = ['MNIST', 'CIFAR-10', 'SVHN', 'EMNIST', 'ETH80', 'CalTec101']\n",
    "chL = [10., ]\n",
    "acc = {v:pd.read_csv(\"../RESULTS/variations/\"+v+\"/accuracies.csv\", index_col=0) for v in vars}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6,4, figsize=(15,10))\n",
    "for i,s in enumerate(dss):\n",
    "    chL = 1\n",
    "    for k,v in enumerate(vars):\n",
    "        # Prep data\n",
    "        tmp = acc[v]\n",
    "        tmp = tmp[tmp[\"Dataset\"]==s].reset_index()\n",
    "        \n",
    "        tmp = tmp[[\"Recording Time\",\"Accuracy\",\"Population\",\"Feedback\"]].pivot(index=\"Recording Time\", values=\"Accuracy\", columns=[\"Feedback\",\"Population\"])\n",
    "\n",
    "        # On condition\n",
    "        tmp[\"on\"].reset_index(drop=True).plot(ax=axs[i][0+2*k], legend=False, xlabel=\"\", style=\"o-\", ylim=(0,100))\n",
    "        axs[i][0+2*k].set_xticks([0,1,2],tmp[\"on\"].index.values)\n",
    "        # Off condition\n",
    "        tmp[\"off\"].reset_index(drop=True).plot(ax=axs[i][1+2*k], xlabel=\"\", legend=False, style=\"o-\", ylim=(0,100))\n",
    "        axs[i][1+2*k].set_xticks([0,1,2],tmp[\"on\"].index.values)\n",
    "    axs[i][0].text(-.4, .5,s, transform = axs[i][0].transAxes)\n",
    "    axs[i][3].legend(loc='center left', bbox_to_anchor=(1.0, 0.5), fontsize=7)\n",
    "    \n",
    "axs[0][0].set_title(\"Feedback On\")\n",
    "axs[0][1].set_title(\"Feedback Off\")\n",
    "axs[0][2].set_title(\"Feedback On\")\n",
    "axs[0][3].set_title(\"Feedback Off\")\n",
    "fig.suptitle(\"Trace                                                                                                                            Average\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dss[1]\n",
    "chL = 0\n",
    "vis = []\n",
    "for v in vars:\n",
    "    tmp = acc[v][acc[v][\"Dataset\"]==s]\n",
    "    chL = tmp[\"Chance Level\"].values[0]    \n",
    "    tmp = tmp.sort_values(\"Feedback\")\n",
    "    tmp = tmp.pivot(index=\"Population\", columns=[\"Feedback\", \"Recording Time\"], values=\"Accuracy\").round(2)\n",
    "    tmp = tmp.reindex(columns=sorted(tmp.columns))\n",
    "    vis.append(tmp.loc[pops])\n",
    "print(s)\n",
    "print(chL)\n",
    "pd.concat(vis, axis=1, keys=vars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"trace condition\")\n",
    "tmp = acc[\"trace\"].drop(\"Chance Level\", axis=1).sort_values([\"Feedback\",\"Dataset\",\"Recording Time\",\"Population\"])\n",
    "fTrace = tmp[\"Accuracy\"].values\n",
    "\n",
    "# Feedback Effect\n",
    "print(\"  Feedback effect\")\n",
    "on = tmp[tmp[\"Feedback\"]==\"on\"][\"Accuracy\"].values\n",
    "off = tmp[tmp[\"Feedback\"]==\"off\"][\"Accuracy\"].values\n",
    "print(sp.stats.ttest_rel(on, off, alternative=\"less\"))\n",
    "# Time Effect\n",
    "t30 = tmp[tmp[\"Recording Time\"]==30][\"Accuracy\"].values\n",
    "t42 = tmp[tmp[\"Recording Time\"]==42][\"Accuracy\"].values\n",
    "t100 = tmp[tmp[\"Recording Time\"]==100][\"Accuracy\"].values\n",
    "print(\"    t30 > t42\")\n",
    "print(sp.stats.ttest_rel(t30, t42, alternative=\"greater\"))\n",
    "print(\"    t42 > t100\")\n",
    "print(sp.stats.ttest_rel(t42, t100, alternative=\"greater\"))\n",
    "\n",
    "\n",
    "print(\"average condition\")\n",
    "tmp = acc[\"average\"].drop(\"Chance Level\", axis=1).sort_values([\"Feedback\",\"Dataset\",\"Recording Time\",\"Population\"])\n",
    "fAvg = tmp[\"Accuracy\"].values\n",
    "# Feedback Effect\n",
    "print(\"  Feedback effect\")\n",
    "on = tmp[tmp[\"Feedback\"]==\"on\"][\"Accuracy\"].values\n",
    "off = tmp[tmp[\"Feedback\"]==\"off\"][\"Accuracy\"].values\n",
    "print(sp.stats.ttest_rel(on, off, alternative=\"two-sided\"))\n",
    "# Time Effect\n",
    "t30 = tmp[tmp[\"Recording Time\"]==30][\"Accuracy\"].values\n",
    "t42 = tmp[tmp[\"Recording Time\"]==42][\"Accuracy\"].values\n",
    "t100 = tmp[tmp[\"Recording Time\"]==100][\"Accuracy\"].values\n",
    "print(\"    t30 > t42\")\n",
    "print(sp.stats.ttest_rel(t30, t42, alternative=\"greater\"))\n",
    "print(\"    t42 > t100\")\n",
    "print(sp.stats.ttest_rel(t42, t100, alternative=\"greater\"))\n",
    "print(\"    t30 > t100\")\n",
    "print(sp.stats.ttest_rel(t30, t100, alternative=\"greater\"))\n",
    "\n",
    "print(\"Design Differences: trace greater than average\")\n",
    "print(sp.stats.ttest_rel(fTrace, fAvg, alternative=\"greater\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"trace condition\")\n",
    "tmp = acc[\"trace\"].drop(\"Chance Level\", axis=1).sort_values([\"Feedback\",\"Dataset\",\"Recording Time\",\"Population\"])\n",
    "tmp = tmp[tmp[\"Dataset\"]!=\"ETH80\"]\n",
    "tmp = tmp[tmp[\"Dataset\"]!=\"CalTec101\"]\n",
    "fTrace = tmp[\"Accuracy\"].values\n",
    "\n",
    "# Feedback Effect\n",
    "print(\"  Feedback effect\")\n",
    "on = tmp[tmp[\"Feedback\"]==\"on\"][\"Accuracy\"].values\n",
    "off = tmp[tmp[\"Feedback\"]==\"off\"][\"Accuracy\"].values\n",
    "print(sp.stats.ttest_rel(on, off, alternative=\"less\"))\n",
    "# Time Effect\n",
    "t30 = tmp[tmp[\"Recording Time\"]==30][\"Accuracy\"].values\n",
    "t42 = tmp[tmp[\"Recording Time\"]==42][\"Accuracy\"].values\n",
    "t100 = tmp[tmp[\"Recording Time\"]==100][\"Accuracy\"].values\n",
    "print(\"    t30 > t42\")\n",
    "print(sp.stats.ttest_rel(t30, t42, alternative=\"greater\"))\n",
    "print(\"    t42 > t100\")\n",
    "print(sp.stats.ttest_rel(t42, t100, alternative=\"greater\"))\n",
    "\n",
    "\n",
    "print(\"average condition\")\n",
    "tmp = acc[\"average\"].drop(\"Chance Level\", axis=1).sort_values([\"Feedback\",\"Dataset\",\"Recording Time\",\"Population\"])\n",
    "tmp = tmp[tmp[\"Dataset\"]!=\"ETH80\"]\n",
    "tmp = tmp[tmp[\"Dataset\"]!=\"CalTec101\"]\n",
    "fAvg = tmp[\"Accuracy\"].values\n",
    "# Feedback Effect\n",
    "print(\"  Feedback effect\")\n",
    "on = tmp[tmp[\"Feedback\"]==\"on\"][\"Accuracy\"].values\n",
    "off = tmp[tmp[\"Feedback\"]==\"off\"][\"Accuracy\"].values\n",
    "print(sp.stats.ttest_rel(on, off, alternative=\"two-sided\"))\n",
    "# Time Effect\n",
    "t30 = tmp[tmp[\"Recording Time\"]==30][\"Accuracy\"].values\n",
    "t42 = tmp[tmp[\"Recording Time\"]==42][\"Accuracy\"].values\n",
    "t100 = tmp[tmp[\"Recording Time\"]==100][\"Accuracy\"].values\n",
    "print(\"    t30 > t42\")\n",
    "print(sp.stats.ttest_rel(t30, t42, alternative=\"greater\"))\n",
    "print(\"    t42 > t100\")\n",
    "print(sp.stats.ttest_rel(t42, t100, alternative=\"greater\"))\n",
    "\n",
    "print(\"Design Differences: trace greater than average\")\n",
    "print(sp.stats.ttest_rel(fTrace, fAvg, alternative=\"greater\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Design Differences: trace greater than average\")\n",
    "print(sp.stats.ttest_rel(fTrace, fAvg, alternative=\"greater\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as lr\n",
    "from sklearn.preprocessing import PolynomialFeatures as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in vars:\n",
    "    np.set_printoptions(precision=2)\n",
    "    tmp = acc[v]\n",
    "    tmp[\"Feedback\"] = tmp[\"Feedback\"].replace([\"on\",\"off\"], [1,0])\n",
    "    tmp[\"Population\"] = tmp[\"Population\"].replace(pops, [0,0,1,1,2,2,3,3])\n",
    "    tmp = tmp[tmp[\"Dataset\"]!=\"ETH80\"]\n",
    "    tmp = tmp[tmp[\"Dataset\"]!=\"CalTec101\"]\n",
    "    y = tmp[\"Accuracy\"]\n",
    "    X = tmp[[\"Feedback\", \"Population\", \"Recording Time\",\"Dataset\"]]\n",
    "    X = pd.get_dummies(X).values\n",
    "    feats = pf(degree=2, include_bias=False, interaction_only=True)\n",
    "    X_ = X#feats.fit_transform(X)\n",
    "    mod = lr().fit(X_, y)\n",
    "    print(v+\" model: R^2 = \"+str(mod.score(X_, y)))\n",
    "#    print(feats.get_feature_names_out([\"f\",\"p\",\"r\"]))\n",
    "    print(mod.coef_)\n",
    "    print(mod.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
